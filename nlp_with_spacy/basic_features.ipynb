{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic features of spaCy library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preliminary actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ pip install spacy numpy pandas scikit-learn matplotlib\n",
    "$ python -m spacy download en_core_web_sm en_core_web_lg\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the english model (and thus data associated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Segmenting text into words, punctuations marks etc.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "is\n",
      "looking\n",
      "at\n",
      "buying\n",
      "U.K.\n",
      "startup\n",
      "for\n",
      "$\n",
      "1\n",
      "billion\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple</td>\n",
       "      <td>is</td>\n",
       "      <td>looking</td>\n",
       "      <td>at</td>\n",
       "      <td>buying</td>\n",
       "      <td>U.K.</td>\n",
       "      <td>startup</td>\n",
       "      <td>for</td>\n",
       "      <td>$</td>\n",
       "      <td>1</td>\n",
       "      <td>billion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0   1        2   3       4     5        6    7  8  9       10\n",
       "0  Apple  is  looking  at  buying  U.K.  startup  for  $  1  billion"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(data={str(key): [token.text] for (key, token) in enumerate(doc)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization rules\n",
    "\n",
    "* SpaCy can split complex, nested tokens like combinations of abbreviations and multiple punctuation marks.\n",
    "* Tokenizer exceptions strongly depend on the specifics of the individual language. \n",
    "* Each language has its own subclass like English or German, that loads in lists of hard-coded data and exception rules.\n",
    "\n",
    "![Alt text](https://spacy.io/tokenization-57e618bd79d933c4ccd308b5739062d6.svg)\n",
    "\n",
    "### Customization of the default tokenization rules\n",
    "\n",
    "* Really crucial for uncommon use cases\n",
    "* E.g. add rules for specific abbreviations in technical reports, ...\n",
    "* Most of the time, better impact on performance than spending time on model selection or hyper-parameter tuning\n",
    "* More information on how to customize rules with spaCy [here](https://spacy.io/usage/linguistic-features#tokenization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Disregard some spelling variations useless for machine processing\n",
    "* E.g. connect, connection, connecting, connected, etc. => **connect**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>LEMMA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>connect</td>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>connection</td>\n",
       "      <td>connection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>connecting</td>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connected</td>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         TEXT       LEMMA\n",
       "0     connect     connect\n",
       "1  connection  connection\n",
       "2  connecting     connect\n",
       "3   connected     connect"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implementing lemmatization\n",
    "lem = nlp(\"connect connection connecting connected\")\n",
    "# finding lemma for each word\n",
    "pd.DataFrame.from_dict({\n",
    "    \"TEXT\": [token.text for token in lem],\n",
    "    \"LEMMA\": [token.lemma_ for token in lem],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spaCy’s Statistical Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Power engines** of spaCy\n",
    "* Used to perform several NLP tasks such as part-of-speech tagging, named entity recognition, word embeddings and dependency parsing.\n",
    "\n",
    "List of the different statistical models in spaCy along with their specifications:\n",
    "\n",
    "* **en_core_web_sm**: English multi-task CNN trained on OntoNotes. Size — 11 MB\n",
    "* **en_core_web_md**: English multi-task CNN trained on OntoNotes, with GloVe vectors trained on Common Crawl. Size — 91 MB\n",
    "* **en_core_web_lg**: English multi-task CNN trained on OntoNotes, with GloVe vectors trained on Common Crawl. Size — 789 MB\n",
    "\n",
    "Importing these models:\n",
    "```bash\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-of-speech tags and dependencies "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part-of-Speech tagging (POS)**\n",
    "> Assigning word types to tokens, like verb or noun.\n",
    "\n",
    "**Dependency Parsing**\n",
    "> Assigning syntactic dependency labels, describing the relations between individual tokens, like subject or object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>LEMMA</th>\n",
       "      <th>POS</th>\n",
       "      <th>TAG</th>\n",
       "      <th>DEP</th>\n",
       "      <th>SHAPE</th>\n",
       "      <th>STOP WORD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple</td>\n",
       "      <td>Apple</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>aux</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>looking</td>\n",
       "      <td>look</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBG</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>at</td>\n",
       "      <td>at</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>prep</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>buying</td>\n",
       "      <td>buy</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBG</td>\n",
       "      <td>pcomp</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>U.K.</td>\n",
       "      <td>U.K.</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>compound</td>\n",
       "      <td>X.X.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>startup</td>\n",
       "      <td>startup</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>dobj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>for</td>\n",
       "      <td>for</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>prep</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>$</td>\n",
       "      <td>$</td>\n",
       "      <td>SYM</td>\n",
       "      <td>$</td>\n",
       "      <td>quantmod</td>\n",
       "      <td>$</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NUM</td>\n",
       "      <td>CD</td>\n",
       "      <td>compound</td>\n",
       "      <td>d</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>billion</td>\n",
       "      <td>billion</td>\n",
       "      <td>NUM</td>\n",
       "      <td>CD</td>\n",
       "      <td>pobj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TEXT    LEMMA    POS  TAG       DEP  SHAPE  STOP WORD\n",
       "0     Apple    Apple  PROPN  NNP     nsubj  Xxxxx      False\n",
       "1        is       be    AUX  VBZ       aux     xx       True\n",
       "2   looking     look   VERB  VBG      ROOT   xxxx      False\n",
       "3        at       at    ADP   IN      prep     xx       True\n",
       "4    buying      buy   VERB  VBG     pcomp   xxxx      False\n",
       "5      U.K.     U.K.  PROPN  NNP  compound   X.X.      False\n",
       "6   startup  startup   NOUN   NN      dobj   xxxx      False\n",
       "7       for      for    ADP   IN      prep    xxx       True\n",
       "8         $        $    SYM    $  quantmod      $      False\n",
       "9         1        1    NUM   CD  compound      d      False\n",
       "10  billion  billion    NUM   CD      pobj   xxxx      False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "\n",
    "pd.DataFrame.from_dict({\n",
    "    \"TEXT\": [token.text for token in doc],\n",
    "    \"LEMMA\": [token.lemma_ for token in doc],\n",
    "    \"POS\": [token.pos_ for token in doc],\n",
    "    \"TAG\": [token.tag_ for token in doc],\n",
    "    \"DEP\": [token.dep_ for token in doc],\n",
    "    \"SHAPE\": [token.shape_ for token in doc],\n",
    "    \"STOP WORD\": [token.is_stop for token in doc]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Text__: The original word text.\n",
    "* __Lemma__: The base form of the word.\n",
    "* __POS__: The simple UPOS part-of-speech tag.\n",
    "* __Tag__: The detailed part-of-speech tag.\n",
    "* __Dep__: Syntactic dependency, i.e. the relation between tokens.\n",
    "* __Shape__: The word shape – capitalization, punctuation, digits.\n",
    "* __is stop__: Is the token part of a stop list, i.e. the most common words of the language?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"1f13cf42172f4ec2acfe7d25083b0c8b-0\" class=\"displacy\" width=\"1975\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Apple</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">looking</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">at</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">buying</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">U.K.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">startup</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">$</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">SYM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">1</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">billion</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1f13cf42172f4ec2acfe7d25083b0c8b-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,89.5 395.0,89.5 395.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1f13cf42172f4ec2acfe7d25083b0c8b-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1f13cf42172f4ec2acfe7d25083b0c8b-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1f13cf42172f4ec2acfe7d25083b0c8b-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1f13cf42172f4ec2acfe7d25083b0c8b-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1f13cf42172f4ec2acfe7d25083b0c8b-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M565.0,266.5 L573.0,254.5 557.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1f13cf42172f4ec2acfe7d25083b0c8b-0-3\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1f13cf42172f4ec2acfe7d25083b0c8b-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M740.0,266.5 L748.0,254.5 732.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1f13cf42172f4ec2acfe7d25083b0c8b-0-4\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1f13cf42172f4ec2acfe7d25083b0c8b-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,266.5 L937,254.5 953,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1f13cf42172f4ec2acfe7d25083b0c8b-0-5\" stroke-width=\"2px\" d=\"M770,264.5 C770,89.5 1095.0,89.5 1095.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1f13cf42172f4ec2acfe7d25083b0c8b-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1095.0,266.5 L1103.0,254.5 1087.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1f13cf42172f4ec2acfe7d25083b0c8b-0-6\" stroke-width=\"2px\" d=\"M770,264.5 C770,2.0 1275.0,2.0 1275.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1f13cf42172f4ec2acfe7d25083b0c8b-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1275.0,266.5 L1283.0,254.5 1267.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1f13cf42172f4ec2acfe7d25083b0c8b-0-7\" stroke-width=\"2px\" d=\"M1470,264.5 C1470,89.5 1795.0,89.5 1795.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1f13cf42172f4ec2acfe7d25083b0c8b-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,266.5 L1462,254.5 1478,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1f13cf42172f4ec2acfe7d25083b0c8b-0-8\" stroke-width=\"2px\" d=\"M1645,264.5 C1645,177.0 1790.0,177.0 1790.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1f13cf42172f4ec2acfe7d25083b0c8b-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1645,266.5 L1637,254.5 1653,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1f13cf42172f4ec2acfe7d25083b0c8b-0-9\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,2.0 1800.0,2.0 1800.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1f13cf42172f4ec2acfe7d25083b0c8b-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1800.0,266.5 L1808.0,254.5 1792.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Labelling named “real-world” objects, like persons, companies or locations.\n",
    "\n",
    "[List of all entities](https://spacy.io/api/annotation#named-entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>START</th>\n",
       "      <th>END</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Companies, agencies, institutions.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.K.</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>GPE</td>\n",
       "      <td>Geopolitical entity, i.e. countries, cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$1 billion</td>\n",
       "      <td>44</td>\n",
       "      <td>54</td>\n",
       "      <td>MONEY</td>\n",
       "      <td>Monetary values, including unit.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         TEXT  START  END  LABEL  \\\n",
       "0       Apple      0    5    ORG   \n",
       "1        U.K.     27   31    GPE   \n",
       "2  $1 billion     44   54  MONEY   \n",
       "\n",
       "                                         DESCRIPTION  \n",
       "0                 Companies, agencies, institutions.  \n",
       "1  Geopolitical entity, i.e. countries, cities, s...  \n",
       "2                   Monetary values, including unit.  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "\n",
    "pd.DataFrame.from_dict({\n",
    "    \"TEXT\": [ent.text for ent in doc.ents],\n",
    "    \"START\": [ent.start_char for ent in doc.ents],\n",
    "    \"END\": [ent.end_char for ent in doc.ents],\n",
    "    \"LABEL\": [ent.label_ for ent in doc.ents],\n",
    "    \"DESCRIPTION\": [\"Companies, agencies, institutions.\",\n",
    "                    \"Geopolitical entity, i.e. countries, cities, states.\",\n",
    "                    \"Monetary values, including unit.\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is looking at buying \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    U.K.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " startup for \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $1 billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customization \n",
    "\n",
    "* You can add your own entities\n",
    "* And retrain a model (more information [here](https://spacy.io/usage/training))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word vectors and similarity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Comparing words, text spans and documents and how similar they are to each other.\n",
    "\n",
    "* Each word is embedded/represented by a vector of floats.\n",
    "* Similarity between 2 words is determined by the proximity of their vector. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We need to load a larger english model in order to have those vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.3 s, sys: 1.24 s, total: 6.54 s\n",
      "Wall time: 6.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.9847e-01,  1.8087e-01, -8.9119e-02, -2.5626e-01,  7.4104e-02,\n",
       "        5.9422e-03, -8.0814e-02, -8.7499e-01,  1.6353e-01,  2.7836e+00,\n",
       "       -8.9134e-01,  3.7017e-02, -5.5995e-01, -2.1853e-01, -3.6847e-01,\n",
       "        4.2609e-01,  2.5508e-02,  1.1834e+00, -5.9869e-02, -1.6261e-02,\n",
       "        3.6331e-01,  1.2664e-01,  3.1424e-01,  2.3845e-02,  5.7331e-02,\n",
       "       -4.7905e-01, -2.3247e-01,  2.3379e-02, -2.9739e-01,  1.0735e-01,\n",
       "        2.9723e-01,  5.4123e-02, -2.6837e-01,  4.8272e-01, -4.8055e-02,\n",
       "       -1.0766e-02,  1.6169e-01, -7.4395e-02,  1.2789e-03, -6.1155e-02,\n",
       "        2.4258e-01,  1.4165e-02,  8.3789e-02, -3.5793e-01, -4.8655e-02,\n",
       "        1.1436e-01,  2.7535e-01, -9.2720e-01,  3.2332e-01,  1.6197e-01,\n",
       "       -2.6260e-01, -3.2542e-01,  1.8347e-01,  5.7849e-01,  1.9925e-01,\n",
       "       -3.7611e-01,  1.8520e-01,  1.3349e-01,  1.9571e-01,  5.1844e-01,\n",
       "        2.0733e-01,  2.0470e-01,  8.3850e-02,  4.2725e-01,  1.1571e-01,\n",
       "       -1.2066e-01, -7.6344e-02,  2.2959e-01, -1.9066e-01,  2.8804e-01,\n",
       "       -4.8705e-02, -1.6430e-01, -9.8883e-02, -3.7394e-01,  3.3152e-02,\n",
       "        4.5618e-02,  2.8564e-01, -3.3728e-01, -2.8675e-01, -2.8868e-01,\n",
       "       -1.8131e-01,  6.1240e-01,  1.6237e-01, -2.2660e-01, -3.7512e-02,\n",
       "        2.1622e-01,  4.1143e-01,  4.1526e-01,  4.8579e-01,  3.4196e-02,\n",
       "        1.1097e-02, -4.2380e-02, -5.8883e-02, -2.5180e-01, -1.1827e-01,\n",
       "       -6.5252e-02,  4.3805e-01,  4.2373e-01, -3.5036e-01,  2.0297e-01,\n",
       "       -9.6745e-02,  5.7277e-01, -1.0347e-01,  3.8731e-02,  1.0371e-01,\n",
       "       -4.1211e-01,  1.6263e-01,  9.9873e-02, -1.9250e-02, -3.4607e-01,\n",
       "       -1.3904e-01,  9.3622e-02,  1.1864e-01, -1.5903e-02,  4.8909e-01,\n",
       "        2.2709e-01, -9.8584e-02,  2.4182e-01,  2.1903e-02,  2.8252e-01,\n",
       "       -2.1217e-01,  2.7143e-01, -2.4541e-01, -5.2238e-01,  2.2886e-01,\n",
       "       -2.6915e-01, -7.0856e-02, -1.4449e-01,  1.7106e-01,  4.7452e-02,\n",
       "       -1.5870e-01,  1.8143e-01, -1.6997e-02, -1.5448e-01,  4.7205e-01,\n",
       "        3.1468e-01,  2.3606e-01,  3.5544e-01,  4.6862e-01, -1.5596e-01,\n",
       "       -1.7340e+00, -1.9391e-01, -2.3963e-02, -3.6020e-01,  4.6535e-02,\n",
       "        2.5813e-01, -9.3215e-02,  2.6950e-01,  2.6694e-01, -1.5030e-01,\n",
       "       -2.0352e-02,  1.8663e-01, -1.9440e-01,  2.3475e-01,  3.4072e-01,\n",
       "       -7.1621e-02,  2.2388e-01, -2.3374e-01,  1.4200e-02, -1.4635e-01,\n",
       "        6.6203e-02, -1.3022e-01, -1.9029e-01,  2.0700e-01,  2.0488e-01,\n",
       "       -5.5457e-01,  3.3125e-01,  1.8895e-01,  6.0863e-01,  2.4981e-01,\n",
       "       -2.1294e-01,  2.0438e-01, -2.1388e-01, -9.2709e-03, -3.2134e-01,\n",
       "       -2.7341e-01, -5.3715e-02,  4.4432e-01, -5.6145e-02,  1.9701e-01,\n",
       "        4.9993e-01, -7.0837e-01,  1.6883e-01, -2.1141e-01, -9.5209e-02,\n",
       "       -2.9795e-02, -7.8936e-02, -2.7381e-01,  3.5855e-01, -1.7869e-01,\n",
       "       -4.1047e-01,  4.8600e-02,  2.7462e-02,  1.1432e-01, -7.6645e-02,\n",
       "        3.2180e-01, -2.4885e-01, -4.2627e-01, -1.6614e-01,  1.6740e-01,\n",
       "       -2.1145e-01,  1.7912e-01,  3.7599e-01, -5.1378e-01,  7.2899e-02,\n",
       "       -1.3659e-01,  1.1925e-01,  3.0539e-02,  2.2776e-01, -2.6466e-01,\n",
       "       -2.8589e-01,  2.8825e-02,  2.5696e-01, -4.6584e-02,  2.1268e-01,\n",
       "       -2.8677e-01,  2.7728e-01, -5.6491e-02, -1.7809e-01,  3.4237e-01,\n",
       "       -5.7061e-02, -6.0279e-02, -1.2577e-01,  1.3695e-01,  1.9769e-01,\n",
       "        1.6630e-01, -2.5674e-01,  1.7000e-01, -3.5881e-01, -3.2292e-01,\n",
       "        3.8045e-01,  6.2803e-02, -2.2209e-01,  2.9701e-01,  5.6837e-02,\n",
       "       -2.7707e-01,  1.1020e-01, -3.1815e-01, -4.6311e-02, -2.8384e-01,\n",
       "       -3.4146e-01,  1.1606e-01,  4.3806e-02,  5.8888e-01, -2.2216e-01,\n",
       "       -2.2103e-01,  3.6901e-01, -5.0477e-01, -1.3206e-01, -5.7208e-01,\n",
       "       -2.5279e-01,  5.1948e-02,  4.1786e-01, -1.3912e-01,  1.7719e-01,\n",
       "        4.1387e-01,  3.6797e-01, -2.6381e-01,  1.4578e-01, -3.0316e-01,\n",
       "       -9.4649e-02,  6.3837e-02,  1.3826e-01, -1.8213e-01,  1.7888e-01,\n",
       "       -1.8555e-01, -1.9941e-01, -1.5132e-01, -1.1393e+00,  1.5898e-01,\n",
       "       -2.9225e-01,  2.0079e-01, -4.9275e-02, -8.0235e-01,  1.2834e-02,\n",
       "       -8.9354e-02, -3.0374e-01,  5.6119e-01, -2.0220e-02,  2.9735e-02,\n",
       "        5.8468e-01, -1.0082e-01, -4.7442e-01, -1.2492e-03, -1.7756e-01,\n",
       "        3.0101e-01,  5.8639e-01,  1.2706e-01, -4.8098e-01, -9.8582e-02,\n",
       "       -2.7866e-01, -3.8891e-01,  5.3706e-02,  7.9971e-01, -3.8533e-01,\n",
       "        2.8433e-01,  3.5182e-02, -2.4263e-01, -3.5183e-02, -2.9661e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_token = nlp(\"house\")\n",
    "house_vector = house_token.vector\n",
    "print(house_vector.shape)\n",
    "house_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>HAS VECTOR</th>\n",
       "      <th>IS OOV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dog</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cat</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>banana</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>afskfsd</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TEXT  HAS VECTOR  IS OOV\n",
       "0      dog        True   False\n",
       "1      cat        True   False\n",
       "2   banana        True   False\n",
       "3  afskfsd       False    True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = nlp(\"dog cat banana afskfsd\")\n",
    "\n",
    "pd.DataFrame.from_dict({\n",
    "    \"TEXT\": [token.text for token in tokens],\n",
    "    \"HAS VECTOR\": [token.has_vector for token in tokens],\n",
    "    \"IS OOV\": [token.is_oov for token in tokens],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If your application will benefit from a large vocabulary with more vectors, you should consider using one of the larger models or loading in a full vector package, for example, **en_vectors_web_lg**, which includes over 1 million unique vectors.\n",
    "* You can find [here](https://spacy.io/models/en-starters) most of the state of the art pretrained word representations (e.g. BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat and Dog similarity: 0.80\n",
      "Cat and Banana similarity: 0.28\n"
     ]
    }
   ],
   "source": [
    "dog_token = tokens[0]\n",
    "cat_token = tokens[1]\n",
    "banana_token = tokens[2]\n",
    "print(\"Cat and Dog similarity: {0:.2f}\".format(dog_token.similarity(cat_token)))\n",
    "print(\"Cat and Banana similarity: {0:.2f}\".format(cat_token.similarity(banana_token)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are Stop Words?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Common words in a vocabulary which are of little value when considering word frequencies in text. \n",
    "* They don't provide much useful information about what the sentence is telling the reader.\n",
    "\n",
    "> Example: \"the\",\"and\",\"a\",\"are\",\"is\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stop words: 326\n",
      "First ten stop words: ['herself', 'her', '‘s', 'alone', 'being', 'besides', 'whether', 'it', 'we', 'well', 'them', 'everywhere', 'around', 'due', 'however', 'along', 'what', 'throughout', 'between', 'n‘t']\n"
     ]
    }
   ],
   "source": [
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "#Printing the total number of stop words:\n",
    "print('Number of stop words: %d' % len(spacy_stopwords))\n",
    "#Printing first ten stop words:\n",
    "print('First ten stop words: %s' % list(spacy_stopwords)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Sentence: [Apple, looking, buying, U.K., startup, $, 1, billion]\n"
     ]
    }
   ],
   "source": [
    "sentence = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "\n",
    "doc_without_stop_words = []\n",
    "for word in sentence:\n",
    "    if word.is_stop==False:\n",
    "        doc_without_stop_words.append(word)\n",
    "print(\"Filtered Sentence:\",doc_without_stop_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IpyKernel Clinique Engie",
   "language": "python",
   "name": "clinique_engie"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
